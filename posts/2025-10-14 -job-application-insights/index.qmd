---
title: "Minha jornada de 3 meses e 400 candidaturas: insights de dados para recoloca√ß√£o"
author: "√ârika Borelli"
date: "2025-10-27"
categories: [code, analysis, job]
image: "image.jpg"
---

Analisei meu hist√≥rico de candidaturas e identifiquei padr√µes sobre o tempo de resposta, as ferramentas mais exigidas e o tipo de vaga que gerou maior retorno das empresas. Neste post apresento os principais insights obtidos nessa jornada, com visualiza√ß√µes e reflex√µes pr√°ticas para quem tamb√©m est√° buscando recoloca√ß√£o na √°rea de dados.

## Como os dados foram obtidos

| Etapa | Descri√ß√£o |
|------------------------------------|------------------------------------|
| **Fonte dos dados** | Cart√µes de vagas no meu Trello + logs de atividades |
| **Pr√©-processamento** | Python e R, com uso de `dplyr`, `tibble`, `lubridate` e `tidytext` |
| **N√∫mero de observa√ß√µes** | Total de candidaturas avaliadas |

## Principais aspectos analisados

-   Volume total de candidaturas

-   Tempo at√© resposta das empresas\
    Distribui√ß√£o, m√©dia e mediana por tipo de retorno

-   Idioma predominante das vagas

-   Palavras-chave e ferramentas t√©cnicas mais mencionadas

-   Taxa de resposta por tipo de posi√ß√£o

## Dura√ß√£o do processo de candidaturas

```{r}
#| echo: false
#| message: false
#| include: false
box::use(
    readr[read_csv],
  dplyr[arrange, group_by, filter, mutate,
        summarise, n, left_join, select,
        rename, join_by, ungroup, across,
        if_else, first, case_when, count,
         desc, distinct, slice_max,
        bind_rows, pull, row_number,
        n_distinct, slice_head],
  lubridate[dmy, interval, time_length, ymd_hms],
  tidyr[replace_na],
  plotly[plot_ly, layout, add_bars, add_trace, subplot ],
  tibble[tibble],
  stringr[str_to_lower]
)


cards <- read_csv("~/Analises/Trello_analytics/cards_clean.csv")
actions <-  read_csv("~/Analises/Trello_analytics/actions_trello.csv")
comments <- read_csv("~/Analises/Trello_analytics/comments_trello.csv")
requisitos <- read_csv("~/Analises/Trello_analytics/requisitos_limpos_final.csv") |> filter(habilidade != 'analise de dados')



```

```{r}
#| echo: false
#| message: false
#| include: false
# Dura√ß√£o do processo
data_inicio <- min(actions$date, na.rm = TRUE)
data_fim <- dmy("29/08/25")
meses_decimais <- round(time_length(interval(data_inicio, data_fim), "months"),2)

# Total candidaturas
total_candidatura <- cards |>
  summarise( total = n())


```

```{r}
#| echo: false
#| message: false
#| include: false
# Candidaturas com resposta
date_first_action <- actions |>
  filter(data.list.name %in% c("Com resposta", "Finalizado")) |>
  group_by(data.card.id) |>
  filter(date == min(date)) |>
  select(data.list.name, data.card.id, date) |>
  rename(date_first_reply = date, list_name_reply = data.list.name)
  
first_date_card <-  actions |>
  group_by(data.card.id) |>
  filter(date == min(date)) |>
  select(data.list.name, data.card.id, date) |>
  rename(date_first_action= date, list_name_first =data.list.name )

cards_with_answer <- first_date_card |>
  left_join(date_first_action)

answer_duration <- cards_with_answer |>
  filter(!is.na(list_name_reply)) |>
  mutate(
    duration = time_length(interval(ymd_hms( date_first_action), ymd_hms(date_first_reply)), "days")
  ) 

empresas <- cards |> 
  group_by(empresa) |> 
  summarise( total_vagas = n())

unique_empresas  = empresas |> distinct(empresa) |> count()

# Colocar isso logo ap√≥s suas primeiras transforma√ß√µes, antes da se√ß√£o "Distribui√ß√£o das Candidaturas"

date_first_reply <- actions |>
  filter(data.list.name %in% c("Com resposta", "Finalizado")) |>
  group_by(data.card.id) |>
  summarise(
    date_first_reply = min(date),
    .groups = "drop"
  )

# CRIAR ISSO ANTES da se√ß√£o "Distribui√ß√£o das Candidaturas"

date_first_reply_completo <- actions |>
  filter(data.list.name %in% c("Com resposta", "Finalizado")) |>
  group_by(data.card.id) |>
  summarise(
    list_name_reply = first(data.list.name),  # ‚Üê ESTA COLUNA FALTAVA
    date_first_reply = min(date),
    .groups = "drop"
  )

first_date_card <- actions |>
  group_by(data.card.id) |>
  summarise(
    date_first_action = min(date),
    .groups = "drop"
  )

# BASE PARA STATUS (usada em fonte_status)
cards_base_status <- first_date_card |>
  left_join(date_first_reply_completo, by = "data.card.id") |>
  mutate(
    date_first_action = ymd_hms(date_first_action),
    date_first_reply = ymd_hms(date_first_reply),
    status_final = case_when(
      !is.na(list_name_reply) & list_name_reply == "Com resposta" ~ "Com resposta",
      !is.na(list_name_reply) & list_name_reply == "Finalizado" ~ "Finalizado",
      TRUE ~ "Sem resposta"
    )
  )

# BASE PARA OVERDUE (usada em an√°lises de tempo)
cards_base_overdue <- first_date_card |>
  left_join(date_first_reply_completo, by = "data.card.id") |>
  mutate(
    date_first_action = ymd_hms(date_first_action),
    date_first_reply  = ymd_hms(date_first_reply),
    reply_bucket = if_else(!is.na(date_first_reply), "Com resposta", "Sem resposta"),
    data_limite = if_else(
      reply_bucket == "Sem resposta",
      data_fim,
      date_first_reply
    ),
    duration_days = time_length(interval(date_first_action, data_limite), "days"),
    overdue_15 = duration_days > 15
  )

```

Monitorei minhas candidaturas ao longo de aproximadamente `r meses_decimais` meses. Durante esse per√≠odo, registrei **`r total_candidatura$total` candidaturas** direcionadas a **`r unique_empresas` empresas distintas**, acompanhando todas as movimenta√ß√µes at√© o primeiro retorno, seja ele positivo ou negativo.

Essa janela de acompanhamento permitiu observar tanto a din√¢mica das empresas em cada fase do processo seletivo quanto os momentos em que o mercado se mostrou mais responsivo a novas aplica√ß√µes.

*Dado de refer√™ncia: dura√ß√£o total desde a primeira candidatura registrada at√© 29/08/2025 (data da minha contrata√ß√£o).*

## Distribui√ß√£o das Candidaturas: Idioma, Canais e Tipos de Vaga

```{r}
#| echo: false
#| message: false

lang_summ <- cards |>
  group_by(desc_lang) |>
  summarise(count_id = n())

fonte_summ <- cards |>
  group_by(fonte_standard) |>
  summarise(count_id = n()) |>
  arrange(desc(count_id))

nomes_vagas_summ <- cards |>
  group_by(vaga_standard) |>
  summarise(count_id = n()) |>
  arrange(desc(count_id))

fonte_status <- cards |>
  select(id, fonte_standard) |>
  left_join(cards_base_status |>  # ‚Üê AGORA USA A BASE CORRETA
              select(data.card.id, status_final) |>
              rename(id = data.card.id)) |>
  group_by(fonte_standard, status_final) |>
  summarise(count_id = n()) |>
  arrange(desc(count_id))

# C√°lculos para o texto
total_candidaturas <- sum(lang_summ$count_id)

# Estat√≠sticas de idioma
portugues_pct <- lang_summ |> filter(desc_lang == "Portuguese") |> pull(count_id) / total_candidaturas * 100
ingles_pct <- lang_summ |> filter(desc_lang == "english") |> pull(count_id) / total_candidaturas * 100

# Estat√≠sticas de fontes
top_fonte <- fonte_summ |> slice_max(count_id, n = 1)
top_fonte_nome <- top_fonte$fonte_standard
top_fonte_count <- top_fonte$count_id
top_fonte_pct <- round((top_fonte_count / total_candidaturas) * 100, 1)

# Estat√≠sticas de vagas
top_vaga <- nomes_vagas_summ |> slice_max(count_id, n = 1)
top_vaga_nome <- top_vaga$vaga_standard
top_vaga_count <- top_vaga$count_id
top_vaga_pct <- round((top_vaga_count / total_candidaturas) * 100, 1)

# Taxa de resposta por fonte
taxa_linkedin <- fonte_status |> 
  filter(fonte_standard == "linkedin", status_final == "Com resposta") |> 
  pull(count_id)
total_linkedin <- fonte_summ |> filter(fonte_standard == "linkedin") |> pull(count_id)
taxa_linkedin_pct <- round((taxa_linkedin / total_linkedin) * 100, 1)
```

### Concentra√ß√£o Geogr√°fica e Estrat√©gia de Idioma

```{r}
#| echo: false
#| message: false
# Gr√°fico de pizza - Idioma das vagas
fig <- plot_ly(
  data = lang_summ,
  labels = ~desc_lang,
  values = ~count_id,
  type = "pie",
  hole = 0.6,
  textinfo = "label+percent",
  textfont = list(size = 14, color = "#111827"),
  marker = list(colors = c("#3B82F6", "#F59E0B", "#9CA3AF")),
  showlegend = FALSE
) |>
  layout(
    title = list(
      text = "Idioma das Descri√ß√µes das Vagas",
      font = list(family = "Arial", size = 18, color = "#111827")
    ),
    plot_bgcolor = "#FFFFFF",
    paper_bgcolor = "#FFFFFF"
  )

fig
```

A distribui√ß√£o por idioma revela uma estrat√©gia focada principalmente no mercado brasileiro, com `r round(portugues_pct, 1)`% das vagas em portugu√™s. No entanto, busquei diversificar com oportunidades internacionais, representando `r round(ingles_pct, 1)`% das candidaturas em ingl√™s, uma tentativa de aproveitar minha experi√™ncia internacional e ampliar as possibilidades de atua√ß√£o.

### Domin√¢ncia do LinkedIn como Canal Principal

```{r}
#| echo: false
#| message: false
# Gr√°fico de barras - Top 5 fontes
fig_fonte <- fonte_summ |>
  arrange(desc(count_id)) |>
  filter(fonte_standard != 'none') |>
  head(5) |>
  plot_ly(
    x = ~count_id,
    y = ~reorder(fonte_standard, count_id),
    text = ~count_id,
    type = 'bar',
    orientation = 'h',
    textposition = 'auto',
    marker = list(color = '#3B82F6')
  ) |>
  layout(
    title = list(
      text = "Principais Canais de Candidatura - Top 5",
      font = list(family = "Arial", size = 18, color = "#111827")
    ),
    xaxis = list(title = "N√∫mero de Candidaturas"),
    yaxis = list(title = ""),
    plot_bgcolor = "#FFFFFF",
    paper_bgcolor = "#FFFFFF"
  )

fig_fonte
```

O LinkedIn emergiu como canal dominante, representando `r top_fonte_count` candidaturas (`r top_fonte_pct`% do total). Esta concentra√ß√£o reflete a efic√°cia da plataforma para busca ativa e a frequ√™ncia de atualiza√ß√µes di√°rias que facilitavam a descoberta de oportunidades alinhadas.

Destaque positivo: O LinkedIn tamb√©m mostrou a melhor taxa de convers√£o entre os principais canais, com `r taxa_linkedin_pct`% das candidaturas evoluindo para a fase de entrevistas.

### Foco Estrat√©gico em An√°lise de Dados

```{r}
#| echo: false
#| message: false
# Gr√°fico de barras - Top 5 vagas
fig_vagas <- nomes_vagas_summ |>
  arrange(desc(count_id)) |>
  head(6) |>  # Incluindo o 6¬∫ para mostrar o product analyst
  plot_ly(
    x = ~count_id,
    y = ~reorder(vaga_standard, count_id),
    text = ~count_id,
    type = 'bar',
    orientation = 'h',
    textposition = 'auto',
    marker = list(color = '#10B981')
  ) |>
  layout(
    title = list(
      text = "Tipos de Vaga Mais Frequentes - Top 6",
      font = list(family = "Arial", size = 18, color = "#111827")
    ),
    xaxis = list(title = "N√∫mero de Candidaturas"),
    yaxis = list(title = ""),
    plot_bgcolor = "#FFFFFF",
    paper_bgcolor = "#FFFFFF"
  )

fig_vagas
  
  
```

A an√°lise dos cargos mostra uma evolu√ß√£o consciente na estrat√©gia de aplica√ß√£o. Com o tempo, passei a focar mais em vagas de `r top_vaga_nome`, que representaram `r top_vaga_count` candidaturas (`r top_vaga_pct`%).

Esta mudan√ßa reflete um alinhamento mais estrat√©gico entre as oportunidades do mercado e minhas experi√™ncias pr√°ticas anteriores, priorizando posi√ß√µes onde meu fit t√©cnico e de perfil era mais evidente.

**Distribui√ß√£o do portf√≥lio de vagas:**

  - `r top_vaga_nome` (`r top_vaga_pct`%): Foco principal baseado em experi√™ncia

  - Cientista de Dados (`r round(115/total_candidaturas*100, 1)`%): Busca por oportunidades de crescimento

  - Analista de BI (`r round(50/total_candidaturas*100, 1)`%): Vagas especializadas em visualiza√ß√£o

### Insight Consolidado

Esta tripla an√°lise revela uma estrat√©gia coerente: foco no mercado brasileiro via LinkedIn, com evolu√ß√£o para posi√ß√µes de Analista de Dados que melhor se alinhavam com meu perfil t√©cnico e experi√™ncias anteriores.

A combina√ß√£o 'mercado local + canal dominante + fit de perfil' mostrou-se mais eficaz que abordagens gen√©ricas ou pulverizadas.

## Empresas que me candidatei

```{r}
#| echo: false
#| message: false
empresas_more_than_1 <- empresas |>
  filter(total_vagas > 1)
empresas_more_than_1_count <- empresas_more_than_1 |> count()
total_candidaturas_empresas_more_1 <- empresas_more_than_1$total_vagas |> sum()

```

Nesse per√≠odo de busca por uma nova oportunidade, eu n√£o me limitei a um contato √∫nico com cada organiza√ß√£o. Do total de `r unique_empresas` empresas distintas, `r empresas_more_than_1_count` receberam mais de uma candidatura da minha parte. Sendo que elas foram alvo de `r total_candidaturas_empresas_more_1` candidaturas.

```{r}
#| echo: false
#| message: false
empresas_top_3 <- empresas |>
  arrange(total_vagas |> desc()) |>
  head(3) |>
  left_join(cards |>
  select(id, vaga_standard, empresa)) |>
  left_join(
    cards_base_overdue  |>
      select(data.card.id, reply_bucket, duration_days, overdue_15) |>
      rename(id = data.card.id)
  )
  
top_1 <-  empresas_more_than_1 |>
  arrange(desc(total_vagas)) |>
  head(1) |>
  left_join(empresas_top_3)

top_1_duration <- top_1 |>
  group_by(reply_bucket) |> 
  summarise(duration_avg = mean(duration_days) |> round(2) ,
            count_reply = n())


```

A `r unique(top_1$empresa)` lidera em n√∫mero de candidaturas (`r unique(top_1$total_vagas)`), incluindo vagas para "Analista de Dados" e "Analista de BI". Das aplica√ß√µes enviadas, recebi feedback negativo em `r top_1_duration |> filter(reply_bucket == 'Com resposta') |> pull(count_reply)` casos, com uma m√©dia de `r top_1_duration |> filter(reply_bucket == 'Com resposta') |> pull(duration_avg)` dias para resposta. As demais aplica√ß√µes n√£o obtiveram retorno.

## O Ritmo dos Processos Seletivos

```{r}
#| echo: false
#| message: false

# --- Agregados: total por bucket e quantos "fora do prazo" ---
agg_overdue <- cards_base_overdue  |>
  group_by(reply_bucket) |>
  summarise(
    total_cards   = n(),
    overdue_15    = sum(overdue_15, na.rm = TRUE),
    pct_overdue   = overdue_15 / total_cards,
    .groups = "drop"
  ) |>
  arrange(factor(reply_bucket, levels = c("Com resposta", "Sem resposta")))


# C√°lculos para o texto
com_resposta <- agg_overdue |> filter(reply_bucket == "Com resposta")
pct_com_resposta_fora_prazo <- round(com_resposta$pct_overdue * 100, 1)
total_com_resposta <- com_resposta$total_cards
num_fora_prazo <- com_resposta$overdue_15

sem_resposta <- agg_overdue |> filter(reply_bucket == "Sem resposta")
pct_sem_resposta_fora_prazo <- round(sem_resposta$pct_overdue * 100, 1)
```

A an√°lise do tempo de resposta revela din√¢micas importantes sobre o pacing dos processos seletivos:

Das `r total_com_resposta` candidaturas que obtiveram resposta, `r num_fora_prazo` (`r pct_com_resposta_fora_prazo`%) levaram mais de 15 dias para o primeiro retorno

Entre as `r sem_resposta$total_cards` aplica√ß√µes sem resposta, `r pct_sem_resposta_fora_prazo`% j√° ultrapassaram a marca de duas semanas


## Taxa de Retorno das Candidaturas

```{r}
#| echo: false
#| message: false

# juntar as informa√ß√µes principais
date_first_reply <- actions |>
  filter(data.list.name %in% c("Com resposta", "Finalizado")) |>
  group_by(data.card.id) |>
  summarise(
    list_name_reply = first(data.list.name),
    date_first_reply = min(date),
    .groups = "drop"
  )

first_date_card <- actions |>
  group_by(data.card.id) |>
  summarise(date_first_action = min(date), .groups = "drop")

cards_base <- first_date_card |>
  left_join(date_first_reply, by = "data.card.id") |>
  mutate(
    date_first_action = ymd_hms(date_first_action),
    date_first_reply = ymd_hms(date_first_reply),
    status_final = case_when(
      !is.na(list_name_reply) & list_name_reply == "Com resposta" ~ "Com resposta",
      !is.na(list_name_reply) & list_name_reply == "Finalizado" ~ "Finalizado",
      TRUE ~ "Sem resposta"
    )
  )

agg_status <- cards_base |>
  count(status_final) |>
  mutate(pct = n / sum(n))

# gr√°fico de rosca com 3 categorias
fig <- plot_ly(
  data = agg_status,
  labels = ~status_final,
  values = ~pct,
  type = "pie",
  hole = 0.6,
  textinfo = "label+percent",
  textfont = list(size = 14, color = "#111827"),
  marker = list(colors = c("#3B82F6", "#F59E0B", "#9CA3AF")),  # azul = resposta positiva, laranja = finalizado, cinza = sem resposta
  showlegend = FALSE
) |>
  layout(
    title = list(
      text = "Status of Job Applications",
      font = list(family = "Arial", size = 18, color = "#111827")
    ),
    plot_bgcolor = "#FFFFFF",
    paper_bgcolor = "#FFFFFF"
  )

total_candidaturas <- sum(agg_status$n)
finalizado_count <- agg_status |> filter(status_final == "Finalizado") |> pull(n)
finalizado_pct <- agg_status |> filter(status_final == "Finalizado") |> pull(pct)
com_resposta_count <- agg_status |> filter(status_final == "Com resposta") |> pull(n)
com_resposta_pct <- agg_status |> filter(status_final == "Com resposta") |> pull(pct)
sem_resposta_pct <- agg_status |> filter(status_final == "Sem resposta") |> pull(pct)

fig



```

Para categorizar o destino de cada aplica√ß√£o, classifiquei as candidaturas em tr√™s est√°gios:

- Com resposta: Retorno positivo com continuidade do processo;

-   Finalizado: Resposta encerrando a candidatura;

-   Sem resposta: Nenhum feedback recebido.

A primeira impress√£o ao ver meus dados foi positiva ,aproximadamente `r round(finalizado_pct * 100, 1)`% das candidaturas tiveram algum tipo de resposta.

Por√©m, ao separar as respostas que realmente evolu√≠ram para entrevistas, a realidade mostrou-se mais dura: apenas `r round(com_resposta_pct * 100, 1)`% (`r com_resposta_count` vagas) avan√ßaram no processo.

Os outros `r round(finalizado_pct * 100, 1)`% representavam respostas negativas, enquanto `r round(sem_resposta_pct * 100, 1)`% das aplica√ß√µes permaneceram no sil√™ncio absoluto.

Essa distribui√ß√£o reflete uma din√¢mica comum no mercado de tecnologia: o "funil de candidaturas" √© bastante estreito. Para cada vaga que avan√ßa para a fase de entrevistas, diversas outras encontram respostas negativas ou simplesmente n√£o obt√™m retorno.

O dado me ensinou a import√¢ncia de gerenciar expectativas e entender que o sil√™ncio n√£o √© pessoal, faz parte do processo de busca por oportunidades alinhadas.

## Faster to Hire, Slower to Reject?

```{r}
#| echo: false
#| message: false

dias_resposta_positiva <- answer_duration |> 
  filter(list_name_reply == "Com resposta") |> 
  pull(duration) |> mean() |> round(1)

dias_resposta_negativa <- answer_duration |> 
  filter(list_name_reply == "Finalizado") |> 
  pull(duration) |> mean() |> round(1)

diferenca_dias <- dias_resposta_negativa - dias_resposta_positiva

fig <- answer_duration |>
  group_by(list_name_reply) |>
  summarise(mean_duration = mean(duration) |> round(2)) |>
  plot_ly(
    x = ~mean_duration, 
    y = ~list_name_reply,
    type = 'bar', 
    orientation = 'h',
    textposition = 'auto', 
    text = ~mean_duration,
    marker = list(color = c("#3B82F6", "#9CA3AF")),
    textfont = list(color = "#FFFFFF", size = 14)
  )

fig |>
  layout(
    title = list(
      text = "Tempo M√©dio para Resposta das Empresas",
      font = list(family = "Arial", size = 18, color = "#111827")
    ),
    yaxis = list(
      title = list(text = "Tipo de Resposta", font = list(size = 14)),
      categoryorder = "total ascending"
    ),
    xaxis = list(
      title = list(text = "Dias em M√©dia", font = list(size = 14)),
      range = c(0, 18)
    ),
    plot_bgcolor = "#FFFFFF",
    paper_bgcolor = "#FFFFFF",
    font = list(family = "Arial", size = 12, color = "#374151")
  )

```

Nos meus dados: respostas positivas chegam em \~`r dias_resposta_positiva` dias, enquanto rejei√ß√µes formais levam \~`r dias_resposta_negativa` dias em m√©dia.

A an√°lise do tempo de resposta revela um padr√£o contraintuitivo: processos que evoluem para entrevistas tendem a ter retornos mais √°geis.

Enquanto as respostas positivas ("Com resposta") chegaram em m√©dia em `r dias_resposta_positiva` dias, as rejei√ß√µes formais ("Finalizado") levaram `r dias_resposta_negativa` dias, cerca de `r diferenca_dias` dias a mais.

Por que essa diferen√ßa? Este gap de r diferenca_dias dias reflete a din√¢mica interna dos processos seletivos:

-   `r dias_resposta_positiva` dias para avan√ßar: Sinaliza agilidade quando h√° fit imediato - as empresas priorizam contatar bons candidatos antes que sejam captados pela concorr√™ncia

-   `r dias_resposta_negativa` dias para rejeitar: Pode indicar processos com m√∫ltiplas etapas, onde a empresa aguarda conclus√£o de todas as entrevistas antes de enviar respostas padronizadas



```{r}
#| echo: false
#| message: false
# C√°lculos para o texto
outlier_max <- max(answer_duration$duration) |> round(1)
outlier_count <- answer_duration |> filter(duration > 30) |> nrow()
total_respostas <- nrow(answer_duration)
pct_outliers <- round((outlier_count / total_respostas) * 100, 1)

# Estat√≠sticas por grupo
stats_resposta <- answer_duration |>
  group_by(list_name_reply) |>
  summarise(
    mediana = median(duration),
    q1 = quantile(duration, 0.25),
    q3 = quantile(duration, 0.75)
  )
```

```{r}
#| echo: false
#| message: false
fig <- answer_duration |>
  plot_ly(
    y = ~duration, 
    color = ~list_name_reply,
    type = "box",
    boxpoints = "outliers",
    marker = list(color = "#6B7280"),
    line = list(color = "#374151")
  ) |>
  layout(
    title = list(
      text = "Distribui√ß√£o Completa dos Tempos de Resposta",
      font = list(family = "Arial", size = 18, color = "#111827")
    ),
    yaxis = list(
      title = "Dias at√© o Primeiro Retorno",
      rangemode = "tozero"
    ),
    xaxis = list(title = ""),
    plot_bgcolor = "#FFFFFF",
    paper_bgcolor = "#FFFFFF",
    font = list(family = "Arial", size = 12)
  )

fig

```

Enquanto as m√©dias nos d√£o uma vis√£o geral, a distribui√ß√£o completa revela nuances importantes sobre os processos:

-   `r outlier_count` das `r total_respostas` respostas (`r pct_outliers`%) levaram mais de 30 dias

-   O caso mais extremo registrou `r outlier_max` dias entre candidatura e resposta

-   A mediana para respostas positivas foi de `r stats_resposta |> filter(list_name_reply == "Com resposta") |> pull(mediana) |> round(1)` dias, mostrando que a maioria dos retornos √°geis realmente ocorre nas primeiras semanas

**O Ru√≠do dos Dados Manuais**

A an√°lise revelou outliers curiosos ‚Äî como uma resposta registrada ap√≥s r outlier_max dias. Ao investigar, percebi que muitos desses picos vinham do meu pr√≥prio processo de registro no Trello, n√£o necessariamente do tempo real de resposta das empresas.

Esses desvios mostram como o gerenciamento manual pode introduzir ru√≠do nos dados ‚Äî um lembrete importante para qualquer an√°lise baseada em registros pessoais.

**Li√ß√µes para Coleta de Dados Pessoais**

1.  Timing de registro: O momento de mover um card no Trello nem sempre coincide com o recebimento real do email

2.  Consist√™ncia metodol√≥gica: Manter padr√µes rigorosos de registro √© crucial para dados confi√°veis

3.  Contexto matters: Dados extremos sempre merecem uma verifica√ß√£o qualitativa

Mantive o boxplot para mostrar a dispers√£o real. Os outliers refletem mais ru√≠do de registro do que o comportamento das empresas ‚Äî algo comum em dados coletados manualmente que todo analista deve considerar.

## A Evolu√ß√£o da Estrat√©gia de Candidaturas

```{r}
#| echo: false
#| message: false

candidatura_by_day <- actions |>
  filter(data.list.name == 'Aplicados') |>
  group_by(data.card.id) |>
  filter(date == min(date)) |>
  mutate(date = as.Date(date)) |>
  group_by(date) |>
  summarise(total_candidatura = n())


# intervalo total da busca de emprego
inicio <- min(candidatura_by_day$date)
fim <- max(candidatura_by_day$date)

# gera sequ√™ncia de todas as datas entre o primeiro e o √∫ltimo dia
todas_as_datas <- tibble(date = seq.Date(inicio, fim, by = "day"))

# une com os dias em que houve candidatura
dias_com_ou_sem <- todas_as_datas |>
  left_join(candidatura_by_day, by = "date") |>
  mutate(
    aplicou = !is.na(total_candidatura)
  )

# quantos dias sem candidatura
dias_sem <- dias_com_ou_sem |>
  summarise(
    total_dias = n(),
    dias_sem_aplicar = sum(!aplicou),
    pct_sem_aplicar = dias_sem_aplicar / total_dias * 100
  )

# C√°lculos para o texto
total_dias <- nrow(candidatura_by_day)
total_candidaturas_periodo <- sum(candidatura_by_day$total_candidatura)
media_por_dia <- round(mean(candidatura_by_day$total_candidatura), 1)

# Estat√≠sticas de julho
julho_data <- candidatura_by_day |>
  filter(date >= "2025-07-01" & date <= "2025-07-31")
candidaturas_julho <- sum(julho_data$total_candidatura)
dias_com_candidatura_julho <- nrow(julho_data)
media_julho <- round(mean(julho_data$total_candidatura), 1)
pico_maximo <- max(candidatura_by_day$total_candidatura)
```

```{r}
#| echo: false
#| message: false

# Gr√°fico de candidaturas por dia
plot_ly(
  candidatura_by_day,
  x = ~date, y = ~total_candidatura, type = "bar",
  marker = list(color = "#3B82F6", opacity = 0.8)
) |>
  layout(
    shapes = list(
      list(
        type = "rect",
        x0 = "2025-07-01", x1 = "2025-07-31",
        y0 = 0, y1 = max(candidatura_by_day$total_candidatura),
        fillcolor = "rgba(245,158,11,0.2)", line = list(width = 0)
      )
    ),
    title = list(
      text = "Evolu√ß√£o das Candidaturas Di√°rias (Maio‚ÄìAgosto 2025)",
      font = list(size = 18, color = "#111827")
    ),
    xaxis = list(title = "Data"),
    yaxis = list(title = "Candidaturas por Dia"),
    plot_bgcolor = "#FFFFFF",
    paper_bgcolor = "#FFFFFF",
    showlegend = FALSE
  )


```

Ao longo de `r total_dias` dias ativos de busca, enviei `r total_candidaturas_periodo` candidaturas, com uma m√©dia de `r media_por_dia` aplica√ß√µes por dia. Por√©m, os n√∫meros contam uma hist√≥ria muito mais rica do que simples estat√≠sticas.

### As Tr√™s Fases da Busca

1.  In√≠cio Empolgado (Maio-Junho)

```         
- Adapta√ß√£o ao processo de candidaturas

- Curva de aprendizado nas aplica√ß√µes

- Volume moderado enquanto ajustava o ritmo
```

2.  Foco em Entrevistas (Junho)

```         
- Queda natural no volume de novas aplica√ß√µes

- Energia direcionada para processos em andamento

- Estrat√©gia mais seletiva nas novas candidaturas
```

3.  Intensifica√ß√£o Estrat√©gica (Julho)

```         
- `r candidaturas_julho` candidaturas concentradas em `r dias_com_candidatura_julho` dias

- M√©dia de `r media_julho` aplica√ß√µes/dia, quase o dobro do per√≠odo geral

- Pico de `r pico_maximo` candidaturas em um √∫nico dia
```

### O Insight por Tr√°s dos N√∫meros

Julho representou um ponto de virada consciente: ap√≥s avaliar meus resultados iniciais, decidi aumentar significativamente o volume e aplicar para tudo que se encaixava genuinamente no meu perfil. Foi uma estrat√©gia intencional para ampliar o leque de oportunidades e compensar a taxa de convers√£o naturalmente baixa do mercado.

Essa fase intensa n√£o foi sobre quantidade pela quantidade, mas sobre otimizar o funil de candidaturas com base nos aprendizados dos primeiros dois meses.

### O Resultado Dessa Estrat√©gia

A intensifica√ß√£o de julho foi crucial para:

-   Gerar um pipeline robusto de oportunidades

-   Aumentar a diversidade de empresas e tipos de vaga

-   Criar momentum psicol√≥gico durante a busca

-   Resultar na contrata√ß√£o final em agosto

## Ritmo e Consist√™ncia na Busca por Oportunidades

```{r}
#| echo: false
#| message: false
# C√°lculos para o texto
media_aplicacoes <- candidatura_by_day |> 
  summarise(avg_apply = mean(total_candidatura)) |> 
  pull(avg_apply) |> round(1)

max_aplicacoes <- candidatura_by_day |> 
  summarise(max_apply = max(total_candidatura)) |> 
  pull(max_apply)

min_aplicacoes <- candidatura_by_day |> 
  summarise(min_apply = min(total_candidatura)) |> 
  pull(min_apply)

total_dias_periodo <- dias_sem$total_dias
dias_sem_aplicar <- dias_sem$dias_sem_aplicar
pct_sem_aplicar <- dias_sem$pct_sem_aplicar |> round(1)
dias_com_aplicar <- total_dias_periodo - dias_sem_aplicar
```

### O Panorama do Per√≠odo Ativo

`r total_dias_periodo` dias de busca ativa (de `r format(inicio, "%d/%m")` a `r format(fim, "%d/%m/%Y")`)

`r dias_com_aplicar` dias com candidaturas vs `r dias_sem_aplicar` dias sem aplica√ß√µes

`r pct_sem_aplicar`% do tempo dedicado a outras atividades da busca

### A Din√¢mica dos Dias de Aplica√ß√£o

```{r}
#| echo: false
#| message: false
# Estat√≠sticas resumidas
candidatura_by_day |>
  summarise(
    avg_apply = mean(total_candidatura),
    max_apply = max(total_candidatura),
    min_apply = min(total_candidatura)
  ) |> 
  knitr::kable(
    col.names = c("M√©dia por Dia", "M√°ximo em um Dia", "M√≠nimo em um Dia"),
    align = "c"
  )

```

Nos dias em que efetivamente enviei candidaturas, o volume foi significativo:

-   M√©dia de `r media_aplicacoes` vagas/dia nos dias ativos

-   Pico de `r max_aplicacoes` candidaturas em um √∫nico dia

-   M√≠nimo de `r min_aplicacoes` vaga nos dias mais seletivos

### O Verdadeiro Significado dos "Dias Vazios"

Os `r dias_sem_aplicar` dias sem novas aplica√ß√µes (40% do tempo) n√£o representam falta de produtividade, mas sim a natureza multifacetada de uma busca estrat√©gica por emprego."

O que realmente acontecia nesses dias:

‚úÖ Entrevistas e processos t√©cnicos - etapas avan√ßadas consumindo tempo

‚úÖ Avalia√ß√£o de ofertas - an√°lise detalhada de propostas recebidas

‚úÖ Gest√£o do pipeline - acompanhamento de candidaturas pendentes

‚úÖ Busca qualificada - pesquisa por vagas alinhadas ao inv√©s de aplica√ß√µes em massa

‚úÖ Descanso estrat√©gico - evitar burnout em um processo mentalmente desgastante

\*\* Padr√£o de "Compensa√ß√£o Inteligente"\*\*

A an√°lise revela um padr√£o eficiente: dias focados em aplica√ß√µes intensivas (`r media_aplicacoes` vagas/dia) compensavam os per√≠odos dedicados a outras atividades essenciais do processo.

Isso demonstra uma abordagem madura onde quantidade e qualidade se equilibraram conforme as necessidades de cada fase:

-   Dias de volume: Amplia√ß√£o do funil de oportunidades

-   Dias de qualidade: Foco em processos avan√ßados e vagas premium

**Li√ß√£o para Quem Busca Recoloca√ß√£o**

Buscar emprego √© um trabalho em tempo integral que vai muito al√©m de enviar curr√≠culos. A m√©trica importante n√£o √© 'dias sem aplicar', mas sim progresso geral no processo, que inclui entrevistas, networking, estudos e autocuidado.

### Habilidades Mais Demandadas pelo Mercado

```{r}
#| echo: false
#| message: false
  df_in <- requisitos
# 1) filtra e conta
df_clean <- df_in |> filter(habilidade != "analise de dados")

counts <- df_clean |>
  mutate(tipo = str_to_lower(tipo_habilidade)) |>
  count(tipo, habilidade, name = "n")

top_n <- 10
top_tecnica <- counts |>
  filter(tipo == "tecnica") |>
  slice_max(n, n = top_n, with_ties = FALSE) |>
  arrange(desc(n))

top_comport <- counts |>
  filter(tipo == "comportamental") |>
  slice_max(n, n = top_n, with_ties = FALSE) |>
  arrange(desc(n))

# 2) prepara fatores (ordem visual descendente)
top_tecnica <- top_tecnica |> mutate(y = factor(habilidade, levels = rev(habilidade)))
top_comport <- top_comport |> mutate(y = factor(habilidade, levels = rev(habilidade)))


# C√°lculos para o texto - atualizados com seus dados
total_requisitos <- nrow(requisitos)
total_vagas_analisadas <- n_distinct(requisitos$id_vaga)

top_3_tecnicas <- top_tecnica |> slice_head(n = 3) |> pull(habilidade)
top_3_comportamentais <- top_comport |> slice_head(n = 3) |> pull(habilidade)

tecnica_mais_frequente <- top_tecnica |> slice_max(n, n = 1) |> pull(habilidade)
count_tecnica_top <- top_tecnica |> slice_max(n, n = 1) |> pull(n)

comport_mais_frequente <- top_comport |> slice_max(n, n = 1) |> pull(habilidade)
count_comport_top <- top_comport |> slice_max(n, n = 1) |> pull(n)

# Estat√≠sticas adicionais
perc_sql <- round((302 / total_vagas_analisadas) * 100, 1)
perc_python <- round((235 / total_vagas_analisadas) * 100, 1)
perc_comunicacao <- round((326 / total_vagas_analisadas) * 100, 1)
```

Analisei `r total_requisitos` requisitos extra√≠dos de `r total_vagas_analisadas` vagas para identificar quais habilidades eram mais valorizadas pelo mercado. Separei as compet√™ncias em t√©cnicas e comportamentais para entender o perfil profissional mais demandado.

### Top Habilidades T√©cnicas

```{r}
#| echo: false
#| message: false



# 3) cria os dois traces (esquerda: t√©cnica, direita: comportamental)
#    - no painel esquerdo vamos plotar valores positivos mas inverter o xaxis para parecer espelhado
trace_left <- plot_ly(
  top_tecnica,
  x = ~n,
  y = ~y,
  type = "bar",
  orientation = "h",
  name = "T√©cnica",
  marker = list(color = "#1f77b4"),
  text = ~n,
  textposition = "inside",
  hovertemplate = paste("<b>%{y}</b><br>T√©cnica: %{x}<extra></extra>")
)

trace_right <- plot_ly(
  top_comport,
  x = ~n,
  y = ~y,
  type = "bar",
  orientation = "h",
  name = "Comportamental",
  marker = list(color = "#ff7f0e"),
  text = ~n,
  textposition = "inside",
  hovertemplate = paste("<b>%{y}</b><br>Comportamental: %{x}<extra></extra>")
)

# 4) monta os subplots lado a lado
# shareY = FALSE porque os y s√£o categorias diferentes; widths controla propor√ß√£o
fig <- subplot(trace_left, trace_right, nrows = 1, shareY = FALSE, widths = c(0.5, 0.5), titleX = TRUE, titleY = TRUE)

# 5) ajuste das margens / eixos para que o painel direito mostre y labels √† direita
fig <- fig |>
  layout(
    title = "T√©cnicas (esquerda)  |  Comportamentais (direita) ‚Äî Top 10",
    showlegend = TRUE,
    legend = list(orientation = "h", x = 0.25, y = 1.05),
    margin = list(l = 80, r = 80, t = 80, b = 40)
  ) |>
  # painel esquerdo: xaxis (1) normal, yaxis (1) labels √† esquerda (default)
  layout(xaxis = list(title = "# vagas"),
         yaxis = list(title = "", automargin = TRUE)) |>
  # painel direito: xaxis2 e yaxis2 correspondem ao 2¬∫ subplot
  layout(xaxis2 = list(title = "# vagas"),
         yaxis2 = list(title = "", automargin = TRUE, side = "right"))

# 6) opcional: inverter a dire√ß√£o do painel esquerdo (para efeito espelhado)
#    se preferir que o lado esquerdo pare√ßa espelhado ao direito, podemos inverter seu xaxis com autorange = "reversed"
fig <- fig |> layout(xaxis = list(autorange = "reversed"))

fig
```

As habilidades t√©cnicas revelam uma base clara de conhecimentos exigidos:

-   `r tecnica_mais_frequente` √© absoluta: `r count_tecnica_top` men√ß√µes (`r perc_sql`% das vagas)

-   `r top_3_tecnicas[2]` segue como segundo lugar com `r top_tecnica$n[2]` cita√ß√µes (`r perc_python`%)

-   `r top_3_tecnicas[3]` completa o p√≥dio com `r top_tecnica$n[3]` ocorr√™ncias

#### Hierarquia clara de ferramentas:

1.  Banco de dados: SQL (fundamental)

2.  Programa√ß√£o: Python (dominante sobre R)

3.  Visualiza√ß√£o: Power BI (lidera frente ao Tableau)

### Soft Skills: Comunica√ß√£o como Imperativo

No aspecto comportamental, os dados s√£o ainda mais reveladores:

-   `r comport_mais_frequente` √© a soft skill mais citada de toda a an√°lise: `r count_comport_top` men√ß√µes (`r perc_comunicacao`% das vagas)

-   `r top_3_comportamentais[2]` com `r top_comport$n[2]` ocorr√™ncias

-   `r top_3_comportamentais[3]` aparece `r top_comport$n[3]` vezes

Destaque crucial: "Boa comunica√ß√£o" aparece mais que qualquer habilidade t√©cnica, incluindo SQL. Isso refor√ßa que o analista de dados moderno precisa ser, antes de tudo, um comunicador eficaz.

### O Profissional Completo de Dados em 2025

A an√°lise pinta um retrato claro do profissional desejado:

üíª Base T√©cnica N√£o-Negoci√°vel

-   SQL (`r perc_sql`% das vagas) - fundamental para acesso e manipula√ß√£o de dados

-   Python (`r perc_python`%) - para an√°lise estat√≠stica e machine learning

-   Ferramentas de BI - Power BI dominante, mas Tableau ainda relevante

üéØ Compet√™ncias Comportamentais Essenciais

-   Comunica√ß√£o (`r perc_comunicacao`%) - traduzir dados em insights acion√°veis

-   Trabalho em equipe - colabora√ß√£o em ambientes multidisciplinares

-   Resolu√ß√£o de problemas - abordagem anal√≠tica para desafios complexos

### Visualiza√ß√£o por Wordcloud

```{r}
#| echo: false
#| message: false
box::use(tibble[tibble],
         tidytext[unnest_tokens],
         stringr[str_replace_all, str_trim, str_to_lower],
         stopwords[stopwords],
         dplyr[slice_head, if_else],
         wordcloud2[wordcloud2]
         )

bow_wordcloud2 <- function(docs, max_words = 200, language = "pt") {
  df <- tibble(text = docs) |> mutate(doc_id = row_number())
  
  tokens <- df |>
    unnest_tokens(word, text) |>
    mutate(word = str_replace_all(word, "[^\\p{L}\\p{N}]+", " ")) |>
    mutate(word = str_trim(word)) |>
    filter(word != "") |>
    mutate(word = str_to_lower(word))
  
  stop_pt <- stopwords::stopwords("pt")
  # Lista personalizada de palavras para manter - incluindo "comunica√ß√£o"
  palavras_manter <- c("comunica√ß√£o", "comunicacao", "trabalho", "equipe")
  
  freq <- tokens |>
    filter(!(word %in% stop_pt) | word %in% palavras_manter) |>  # Mant√©m palavras importantes
    filter(!word %in% c('boa', 'ser', 'estar')) |>  # Remove outras palavras irrelevantes
    count(word, sort = TRUE) |>
    slice_head(n = max_words)
  
  # rename 'n' para 'freq' e garantir data.frame / numeric
  if ("n" %in% names(freq)) names(freq)[names(freq) == "n"] <- "freq"
  freq <- as.data.frame(freq)
  freq$freq <- as.numeric(freq$freq)

  # conferir o top 5 antes de plotar (debug)
  print(head(freq, 10))
  # wordcloud2 retorna um widget HTML (interativo)
  wordcloud2(freq, size = 1)
}

requisitos_comportamento <-  requisitos |>
  filter(tipo_habilidade == 'comportamental')

requisitos_tecnica <- requisitos |>
  filter(tipo_habilidade == 'tecnica')




```

```{r}
#| echo: false
#| message: false
# Wordcloud habilidades t√©cnicas
bow_wordcloud2(requisitos_tecnica$habilidade, max_words = 100)
```

```{r}
#| echo: false
#| message: false
# Wordcloud habilidades comportamentais
bow_wordcloud2(requisitos_comportamento$habilidade, max_words = 100)
```

### Insight Estrat√©gico para Desenvolvimento

Estes dados orientam prioridades de aprendizado:

1.  SQL √© obrigat√≥rio - aparece em quase todas as vagas t√©cnicas

2.  Python + Power BI formam o stack b√°sico moderno

3.  Comunica√ß√£o n√£o √© opcional - √© a soft skill mais valorizada

4.  R ainda tem espa√ßo (`r top_tecnica$n[8]` men√ß√µes), mas Python domina

"O mercado busca t√©cnicos que comunicam bem, n√£o apenas g√™nios do c√≥digo. A habilidade de explicar insights complexos em termos simples √© t√£o valiosa quanto a capacidade de ger√°-los."
